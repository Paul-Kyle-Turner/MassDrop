{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Malware.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpNS-gNVvXDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "from joblib import dump, load"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9SDMShsarJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "# nltk.download('punkt') # Uncomment this line to download the nltk punkt resource."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCCmsK-ya4sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from statistics import mean\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQNQFzoF9IYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mifs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEExY5TP-Afw",
        "colab_type": "text"
      },
      "source": [
        "Import the data that is being used for the project from within google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeEHTklC8Bcy",
        "colab_type": "code",
        "outputId": "0ce51ff5-bf27-4a07-b013-56a8e17086f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQEMXONEbhc1",
        "colab_type": "code",
        "outputId": "adbb0fd0-d1f9-472f-99de-f954d339b0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir('drive/My Drive/malware')\n",
        "print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/malware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg-j02BKbBX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('all_analysis_data.txt', 'r') as original_data:\n",
        "    api_calls = original_data.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUPoYj8GbCD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_labels = []\n",
        "with open('labels.csv', 'r') as data_labels:\n",
        "    for line in data_labels.readlines():\n",
        "        class_labels.append(line.replace('\\n', ''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7JTIR6_bCGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counts_vectorizer = CountVectorizer(ngram_range=(1,10), max_df=.97, min_df=.03)\n",
        "malware_counts_ngram = counts_vectorizer.fit_transform(api_calls).todense()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgH-19uPbCJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = counts_vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-LiMe4PFwPC",
        "colab_type": "code",
        "outputId": "efd9f4f1-4590-45a8-f3e3-0dfcd4a849fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dump(features, 'features.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['features.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35EJe0VYl6Sh",
        "colab_type": "code",
        "outputId": "16680292-fb18-4b9b-c93f-256c11f702c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dump(malware_counts_ngram, 'counts_matrix.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['counts_matrix.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFNxfjnSbCME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(malware_counts_ngram))\n",
        "print(malware_counts_ngram.shape)\n",
        "print(len(features))\n",
        "print(set(class_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqyUwB6_CzrD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidf_api_calls = tfidf_transformer.fit_transform(malware_counts_ngram)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eyNOUlN9tIb",
        "colab_type": "code",
        "outputId": "59c3a8fe-ea09-4d2e-9de7-ca3485b32415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dump(tfidf_api_calls, 'tfidf_vectors.joblib')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectors.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdrDnNG6x0GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_api_calls = load('tfidf_vectors.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJh30e3fCzzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_neg_dict = dict()\n",
        "name_list = list()\n",
        "for col_name, col_index in zip(features, range(malware_counts_ngram.shape[1])):\n",
        "    name_list.append(col_name)\n",
        "    col_data = malware_counts_ngram[:, col_index]\n",
        "    trojan = 0\n",
        "    worms = 0\n",
        "    downloader = 0\n",
        "    virus = 0\n",
        "    backdoor = 0\n",
        "    dropper = 0\n",
        "    spyware = 0\n",
        "    adware = 0\n",
        "    num = 0\n",
        "    for i in range(col_data.shape[0]):\n",
        "        if col_data[i] == 1:\n",
        "            num += 1\n",
        "            if class_labels[i] == 'Trojan':\n",
        "                trojan += 1\n",
        "            elif class_labels == 'Worms':\n",
        "                worms += 1\n",
        "            elif class_labels == 'Downloader':\n",
        "                downloader += 1\n",
        "            elif class_labels == 'Virus':\n",
        "                virus += 1\n",
        "            elif class_labels == 'Backdoor':\n",
        "                backdoor += 1\n",
        "            elif class_labels == 'Spyware':\n",
        "                spyware += 1\n",
        "            elif class_labels == 'Dropper':\n",
        "                dropper += 1\n",
        "            elif class_labels == 'Adware':\n",
        "                adware += 1\n",
        "    if trojan == 0:\n",
        "        percent_trojan = 0\n",
        "    else:\n",
        "        percent_trojan = float(trojan / num)\n",
        "    if worms == 0:\n",
        "        percent_worms = 0\n",
        "    else:\n",
        "        percent_worms = float(worms / num)\n",
        "    if downloader == 0:\n",
        "        percent_downloader = 0\n",
        "    else:\n",
        "        percent_downloader = float(downloader / num)  \n",
        "    if virus == 0:\n",
        "        percent_virus = 0\n",
        "    else:\n",
        "        percent_virus = float(virus / num) \n",
        "    if backdoor == 0:\n",
        "        percent_backdoor = 0\n",
        "    else:\n",
        "        percent_backdoor = float(backdoor / num) \n",
        "    if dropper == 0:\n",
        "        percent_dropper = 0\n",
        "    else:\n",
        "        percent_dropper = float(dropper / num) \n",
        "    if spyware == 0:\n",
        "        percent_spyware = 0\n",
        "    else:\n",
        "        percent_spyware = float(spyware / num) \n",
        "    if adware == 0:\n",
        "        percent_adware = 0\n",
        "    else:\n",
        "        percent_adware = float(adware / num) \n",
        "        \n",
        "    term_frequency = num / len(class_labels)\n",
        "    benign_neg_dict[col_name] = [trojan, worms, downloader, virus, backdoor, dropper, spyware, adware,\n",
        "                                percent_trojan, percent_worms, percent_downloader, percent_virus, percent_backdoor,\n",
        "                                percent_dropper, percent_spyware, percent_adware, num, term_frequency]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dlzA7hqCz13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_data = pd.DataFrame(benign_neg_dict).T\n",
        "meta_data['Api-Call'] = name_list\n",
        "meta_data.columns = ['trojan', 'worms', 'downloader', 'virus', 'backdoor', 'dropper', 'spyware', 'adware',\n",
        "                                'percent_trojan', 'percent_worms', 'percent_downloader', 'percent_virus', 'percent_backdoor',\n",
        "                                'percent_dropper', 'percent_spyware', 'percent_adware', 'num', 'term_frequency', 'Api-Call']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSpQneJcCzwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vocab_prune(meta, min_dist_away=.05):\n",
        "    vocabulary_prune = set()\n",
        "    for percent, name, i in zip(meta['positive_percent'].tolist(), meta['name'].tolist(), range(meta.shape[0])):\n",
        "        percent = abs(percent - .5)\n",
        "        if percent < min_dist_away:\n",
        "            vocabulary_prune.add(name)\n",
        "    return vocabulary_prune"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VtayBaRru40",
        "colab_type": "text"
      },
      "source": [
        "Create some aggrogate fields for (not \"classification label\").  This is to find features that are specific to each of the malware classifications."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6uQ7SnfsptN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_data['not_trojan'] = meta_data['num'] - meta_data['trojan']\n",
        "meta_data['not_worms'] = meta_data['num'] - meta_data['worms']\n",
        "meta_data['not_downloader'] = meta_data['num'] - meta_data['downloader']\n",
        "meta_data['not_virus'] = meta_data['num'] - meta_data['virus']\n",
        "meta_data['not_backdoor'] = meta_data['num'] - meta_data['backdoor']\n",
        "meta_data['not_spyware'] = meta_data['num'] - meta_data['dropper']\n",
        "meta_data['not_dropper'] = meta_data['num'] - meta_data['spyware']\n",
        "meta_data['not_adware'] = meta_data['num'] - meta_data['adware']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc62kjpx1GyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_data = pd.read_csv('meta_data_malwareAPI_10gram.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q7Co4StJBPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(meta_data.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpTiq1pHHwxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_data.to_csv('meta_data_malwareAPI_10gram.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "debi7_x4Kqn-",
        "colab_type": "text"
      },
      "source": [
        "We got to the new stuff huzzah."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUyj_w6zBPRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(tfidf_api_calls,\n",
        "                                                    class_labels,\n",
        "                                                    test_size=.20,\n",
        "                                                    random_state = 44)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBU4FDP0v3q4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "models = [\n",
        "    RandomForestClassifier(n_estimators=200, max_depth=5, random_state=44),\n",
        "    BernoulliNB(),\n",
        "    MultinomialNB(),\n",
        "    GaussianNB(),\n",
        "    DecisionTreeClassifier(max_depth=10),\n",
        "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=10)),\n",
        "    BaggingClassifier(DecisionTreeClassifier(max_depth=10)),\n",
        "    KNeighborsClassifier(n_neighbors=5),\n",
        "    MLPClassifier(solver='sgd', random_state=44)\n",
        "]\n",
        "set_class_labels = list(set(class_labels))\n",
        "meta_name_list = ['total']\n",
        "idf = None\n",
        "name = 'Malware_API_calls'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FNjV-uUCzth",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta = meta_data\n",
        "        \n",
        "count_vectorizer = CountVectorizer(ngram_range=(1,6), max_df=.97, min_df=.03)\n",
        "counts_vectors = count_vectorizer.fit_transform(api_calls)\n",
        "counts_features = count_vectorizer.get_feature_names()\n",
        "\n",
        "with open(f'features_of_{name}_{str(idf)}', 'wb') as out_features:\n",
        "    pickle.dump(counts_features, out_features)\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "tfidf_vectors = tfidf_transformer.fit_transform(counts_vectors).todense()\n",
        "\n",
        "with open(f'tfidf_vectors_{name}_{str(idf)}.pickle', 'wb') as out_matrix:\n",
        "  pickle.dump(tfidf_vectors, out_matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKGJOxL58MTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def not_class_label(class_label, class_label_list):\n",
        "  return [label if label == class_label else 0 for label in class_label_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoKACdtwxNZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(set(class_labels))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdHAXAVNCTS3",
        "colab_type": "text"
      },
      "source": [
        "binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPyppnjTvjLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'Accuracies_{name}_total.txt', 'w+') as out_file:\n",
        "  out_file.write(f'Scores of tested sklearn classifiers.')\n",
        "  # out_file.write(f'5 Fold Cross Validation Acc for Malware API Calls')\n",
        "  # out_file.write(f'\\nThese next models have all vocabulary\\n')\n",
        "  out_file.close()\n",
        "\n",
        "run_number = 0\n",
        "save_dict = {}\n",
        "\n",
        "for label in set(class_labels):\n",
        "    temp_labels = not_class_label(label, y_train)\n",
        "    temp_y_test = not_class_label(label, y_test)\n",
        "\n",
        "    for model in models:\n",
        "        model_name = model.__class__.__name__\n",
        "\n",
        "        model.fit(x_train.todense(), temp_labels)\n",
        "        pred = model.predict(x_test.todense())\n",
        "\n",
        "        summary = classification_report(temp_y_test, pred, output_dict=True)\n",
        "        save_dict[str(run_number)] = summary\n",
        "        run_number += 1\n",
        "\n",
        "        with open(f'Accuracies_{name}_binary.txt', 'a+') as out_file:\n",
        "            out_file.write(f'Binary class {label}\\n')\n",
        "            out_file.write(f'{model_name}\\n')\n",
        "            pprint.pprint(summary, stream=out_file)\n",
        "            out_file.close()\n",
        "        dump(model, f'{model_name}_{label}.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sge-s6uCR9e",
        "colab_type": "text"
      },
      "source": [
        "norms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ7Y85OGxKOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in models:\n",
        "    model_name = model.__class__.__name__\n",
        "\n",
        "    model.fit(x_train.todense(), y_train)\n",
        "    pred = model.predict(x_test.todense())\n",
        "\n",
        "    summary = classification_report(y_test, pred, output_dict=True)\n",
        "    save_dict[str(run_number)] = summary\n",
        "    run_number += 1\n",
        "\n",
        "    with open(f'Accuracies_{name}_total.txt', 'a+') as out_file:\n",
        "        out_file.write(f'Classification on all labels.\\n')\n",
        "        out_file.write(f'{model_name}\\n')\n",
        "        pprint.pprint(summary, stream=out_file)\n",
        "        out_file.close()\n",
        "    dump(model, f'{model_name}.joblib')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqWHlPt7CPon",
        "colab_type": "text"
      },
      "source": [
        "dont use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmDKBjMzKmVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'Accuracies_{name}.txt', 'w+') as out_file:\n",
        "  out_file.write(f'Adaboost classification report')\n",
        "  out_file.write(f'\\nThese next models have all vocabulary\\n')\n",
        "  out_file.close()\n",
        "\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "\n",
        "  model.fit(x_train.todense(), y_train)\n",
        "  pred = model.predict(x_test.todense())\n",
        "\n",
        "  summary = classification_report(y_test, pred, output_dict=True)\n",
        "\n",
        "  with open(f'Accuracies_{name}.txt', 'a+') as out_file:\n",
        "    out_file.write(f'Using data from {name}\\n')\n",
        "    out_file.write(f'{model_name}\\n')\n",
        "    pprint.pprint(summary, stream=out_file)\n",
        "    out_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58JuK72eKWId",
        "colab_type": "text"
      },
      "source": [
        "This was just for formatting of the files since i made a mistake.  I did not place these within a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAhH7HQ-D9bF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('Accuracies.txt', 'r') as in_file:\n",
        "  with open(f'Accuracies_{name}.txt', 'a') as out_file:\n",
        "    for line in in_file.readlines():\n",
        "      out_file.write(re.sub(r'U','\\nU',line))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKABhZAQIimP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'Accuracies_{name}.txt', 'r') as in_file:\n",
        "  with open('Accuracies.txt', 'a') as out_file:\n",
        "    for line in in_file.readlines():\n",
        "      if re.match(r'U', line):\n",
        "        pass\n",
        "      else:\n",
        "        out_file.write(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DvHzLuxK7Py",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(f'Accuracies.txt', 'r') as in_file:\n",
        "  with open(f'Accuracies_{name}.txt', 'a+') as out_file:\n",
        "    for line in in_file.readlines():\n",
        "      if re.match(r'Mean', line):\n",
        "        pass\n",
        "      else:\n",
        "          temp = line.split('    ')\n",
        "          name = temp[0]\n",
        "          acc_list = temp[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8sMxgmW-NmA",
        "colab_type": "text"
      },
      "source": [
        "We are going to do some mRMR to do some feature selection of the ngrams.  Oh boy this is rough let's use mifs on your on computer and run the decision trees here instead.  Let's not talk about it\n",
        "\n",
        "fuck"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKzYTvKH7_Ba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rand_forest = RandomForestClassifier(n_estimators=1000, max_depth=20, n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijRGDcVFbsxD",
        "colab_type": "text"
      },
      "source": [
        "Let's make some confusion matrix and save them in a pics folder.  Also try to save them in csv and display as a heat map in tab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuGzKxnKzLvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import plot_confusion_matrix, plot_precision_recall_curve, plot_roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "titles = [(\"CM_Normalized \", 'true'), (\"CM\", None)]\n",
        "import csv\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvpKIu30b8av",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "\n",
        "  model = load(model_name + '.joblib')\n",
        "\n",
        "  for title, normalize in titles:\n",
        "\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    disp = confusion_matrix(y_test, y_pred,\n",
        "                            labels = set_class_labels,\n",
        "                            normalize = normalize)\n",
        "    \n",
        "    temp_df = pd.DataFrame(disp, index = set_class_labels, columns= set_class_labels)\n",
        "\n",
        "    ax = sns.heatmap(temp_df, annot=True, linewidths=.05)\n",
        "    \n",
        "    plt.savefig('pics/' + model_name + '_' + title + '_sns.png')\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7z2xXbMTpE9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "\n",
        "  for title, normalize in titles:\n",
        "\n",
        "    for class_name in set_class_labels:\n",
        "\n",
        "      model = load(model_name + '_' + class_name + '.joblib')\n",
        "\n",
        "      temp_labels = not_class_label(class_name, y_train)\n",
        "      temp_y_test = not_class_label(class_name, y_test)\n",
        "\n",
        "      disp = plot_confusion_matrix(model, x_test, temp_y_test,\n",
        "                                  display_labels = set(temp_labels),\n",
        "                                  cmap = plt.cm.Blues,\n",
        "                                  normalize = normalize)\n",
        "      \n",
        "      disp.ax_.set_title(title + '_' + class_name)\n",
        "      \n",
        "      plt.savefig('te_pics/' + model_name + '_' + title + '_' + class_name +'.png')\n",
        "      plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB2L0-MNPxBT",
        "colab_type": "text"
      },
      "source": [
        "ROC curves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilKLlnu4l9N7",
        "colab_type": "text"
      },
      "source": [
        "curve for each model for each binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoSjuaE74kBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(set_class_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tksF01Iyuc40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in models:\n",
        "\n",
        "  model_name = model.__class__.__name__\n",
        "  ax = None\n",
        "\n",
        "  for class_num in range(len(set_class_labels)):\n",
        "    model_t = load(model_name + '_' + set_class_labels[class_num] + '.joblib')\n",
        "\n",
        "    disp = plot_roc_curve(model_t, x_test, y_test,\n",
        "                          name = model_name + '_' + set_class_labels[class_num],\n",
        "                          ax = ax)\n",
        "    ax = plt.gca()\n",
        "\n",
        "  plt.legend(fontsize = 'x-small')\n",
        "  plt.savefig('ROC/models_labels_t/' + model_name + '_roc.png')\n",
        "  plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh3RBgtia5id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for class_num in range(len(set_class_labels)):\n",
        "\n",
        "  ax = None\n",
        "\n",
        "  for model in models:\n",
        "    model_name = model.__class__.__name__\n",
        "\n",
        "    model_t = load(model_name + '_' + set_class_labels[class_num] + '.joblib')\n",
        "\n",
        "    disp = plot_roc_curve(model_t, x_test, y_test,\n",
        "                          name = model_name + '_' + set_class_labels[class_num],\n",
        "                          ax = ax)\n",
        "    ax = plt.gca()\n",
        "\n",
        "  plt.legend(fontsize = 'x-small')\n",
        "  plt.savefig('ROC/labels_models_t/' + set_class_labels[class_num] + '_roc.png')\n",
        "  plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jB1aTZlAbVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TEY0R3JSf9A",
        "colab_type": "text"
      },
      "source": [
        "Let's make some percision recall curves now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt6E30D104T-",
        "colab_type": "code",
        "outputId": "2c1f4d51-cce7-4ba6-cc63-d5cfa1e56654",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import pickle\n",
        "from joblib import dump, load\n",
        "import nltk\n",
        "# nltk.download('punkt') # Uncomment this line to download the nltk punkt resource.\n",
        "from statistics import mean\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import pprint\n",
        "\n",
        "os.chdir('drive/My Drive/malware')\n",
        "#print(os.getcwd())\n",
        "\n",
        "class_labels = []\n",
        "with open('labels.csv', 'r') as data_labels:\n",
        "    for line in data_labels.readlines():\n",
        "        class_labels.append(line.replace('\\n', ''))\n",
        "\n",
        "tfidf_api_calls = load('tfidf_vectors.joblib')\n",
        "\n",
        "def not_class_label(class_label, class_label_list):\n",
        "  return [label if label == class_label else 0 for label in class_label_list]\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(tfidf_api_calls,\n",
        "                                                    class_labels,\n",
        "                                                    test_size=.20,\n",
        "                                                    random_state = 44)\n",
        "\n",
        "models = [\n",
        "    #RandomForestClassifier(n_estimators=200, max_depth=5, random_state=44),\n",
        "    #BernoulliNB(),\n",
        "    #MultinomialNB(),\n",
        "    #GaussianNB(),\n",
        "    #CategoricalNB(),\n",
        "    #DecisionTreeClassifier(max_depth=10),\n",
        "    AdaBoostClassifier(DecisionTreeClassifier(max_depth=10)),\n",
        "    #BaggingClassifier(DecisionTreeClassifier(max_depth=10)),\n",
        "    #KNeighborsClassifier(n_neighbors=5),\n",
        "    #MLPClassifier(solver='sgd', random_state=44)\n",
        "]\n",
        "set_class_labels = list(set(class_labels))\n",
        "meta_name_list = ['total']\n",
        "idf = None\n",
        "name = 'Malware_API_calls'\n",
        "\n",
        "from sklearn.metrics import plot_confusion_matrix, plot_precision_recall_curve, plot_roc_curve\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "titles = [(\"CM_Normalized \", 'true'), (\"CM\", None)]\n",
        "import csv\n",
        "\n",
        "x_test = x_test.todense()\n",
        "\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHOLrWX61XZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for class_num in range(len(set_class_labels)):\n",
        "\n",
        "  for model in models:\n",
        "    model_name = model.__class__.__name__\n",
        "\n",
        "    model_t = load(model_name + '_' + set_class_labels[class_num] + '.joblib')\n",
        "\n",
        "    lin = precision_recall_curve()\n",
        "\n",
        "  plt.legend(fontsize = 'x-small')\n",
        "  plt.savefig('PRCurve/labels_models/' + set_class_labels[class_num] + '_pr.png')\n",
        "  plt.close()\n",
        "  print(class_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeqaeTRiRpaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "\n",
        "  for class_num in range(len(set_class_labels)):\n",
        "    model_t = load(model_name + '_' + set_class_labels[class_num] + '.joblib')\n",
        "\n",
        "    lin = plot_precision_recall_curve(model_t, x_test, y_test,\n",
        "                          name = model_name + '_' + set_class_labels[class_num])\n",
        "\n",
        "  plt.legend(fontsize = 'x-small')\n",
        "  plt.savefig('PRCurve/models_labels/' + model_name + '_pr.png')\n",
        "  plt.close()\n",
        "  print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV81fZZDQnXJ",
        "colab_type": "text"
      },
      "source": [
        "summary of each model\n",
        "\n",
        "col : model_name_id, class_used_for, model_name, summary information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVy-AU8IQnwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_cols = ['id', 'class_label', 'model_name', 'acc',\n",
        "                'weighted avg precision',\n",
        "                'weighted avg recall',\n",
        "                'weighted avg f1-score',\n",
        "               'neg precision', 'neg recall', 'neg f1-score',\n",
        "               'pos precision', 'pos recall', 'pos f1-score']\n",
        "\n",
        "summary_list = []\n",
        "\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "\n",
        "  for class_num in range(len(set_class_labels)):\n",
        "    model_t = load(model_name + '_' + set_class_labels[class_num] + '.joblib')\n",
        "\n",
        "    temp_labels = not_class_label(set_class_labels[class_num], y_train)\n",
        "    temp_y_test = not_class_label(set_class_labels[class_num], y_test)\n",
        "\n",
        "    pred = model_t.predict(x_test)\n",
        "    summary = classification_report(temp_y_test, pred, output_dict=True)\n",
        "\n",
        "    summary_list.append([model_name + '_' + set_class_labels[class_num],\n",
        "                        set_class_labels[class_num],\n",
        "                        model_name,\n",
        "                        summary['accuracy'],\n",
        "                        summary['weighted avg']['precision'],\n",
        "                        summary['weighted avg']['recall'],\n",
        "                        summary['weighted avg']['f1-score'],\n",
        "                        summary['0']['precision'],\n",
        "                        summary['0']['recall'],\n",
        "                        summary['0']['f1-score'],\n",
        "                        summary[set_class_labels[class_num]]['precision'],\n",
        "                        summary[set_class_labels[class_num]]['recall'],\n",
        "                        summary[set_class_labels[class_num]]['f1-score']\n",
        "                        ])\n",
        "\n",
        "summary_df = pd.DataFrame(summary_list, columns = summary_cols)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUfw1FuWA5ux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_cols = ['id', 'class_label', 'model_name', 'acc',\n",
        "                'weighted avg precision',\n",
        "                'weighted avg recall',\n",
        "                'weighted avg f1-score',\n",
        "               'neg precision', 'neg recall', 'neg f1-score',\n",
        "               'pos precision', 'pos recall', 'pos f1-score']\n",
        "\n",
        "summary_list = []\n",
        "\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "\n",
        "  for class_num in range(len(set_class_labels)):\n",
        "    model_t = load(model_name + '_' + set_class_labels[class_num] + '.joblib')\n",
        "\n",
        "    temp_labels = not_class_label(set_class_labels[class_num], y_train)\n",
        "    temp_y_test = not_class_label(set_class_labels[class_num], y_test)\n",
        "\n",
        "    pred = model_t.predict(x_test)\n",
        "    summary = classification_report(temp_y_test, pred, output_dict=True)\n",
        "\n",
        "    summary_list.append([model_name + '_' + set_class_labels[class_num],\n",
        "                        set_class_labels[class_num],\n",
        "                        model_name,\n",
        "                        summary['accuracy'],\n",
        "                        summary['weighted avg']['precision'],\n",
        "                        summary['weighted avg']['recall'],\n",
        "                        summary['weighted avg']['f1-score'],\n",
        "                        summary['0']['precision'],\n",
        "                        summary['0']['recall'],\n",
        "                        summary['0']['f1-score'],\n",
        "                        summary[set_class_labels[class_num]]['precision'],\n",
        "                        summary[set_class_labels[class_num]]['recall'],\n",
        "                        summary[set_class_labels[class_num]]['f1-score']\n",
        "                        ])\n",
        "\n",
        "summary_df = pd.DataFrame(summary_list, columns = summary_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IpGjS41Yv3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_df.to_csv('summary_meta.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHRI_rlUDcFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary_df = pd.read_csv('summary_meta.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8T9mq1jDine",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWfbeGQfAwXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.heatmap(summary_df.iloc[:-1,:].T, annot = True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}